from ply import yacc
from typing import Optional, List

# LEXER / TOKENS
from ..lexer.tokens import TOKENS 
print(TOKENS)   
from ..lexer.lexer import Lexer             

tokens = TOKENS    # tuple of tokens defined in the lexer                          

# AST NODES
from ..core.ast import (
    AstNode,
    LiteralExpr, Identifier,
    UnaryExpr, BinaryExpr, ComparisonExpr, CallExpr, 
)

from ..core.utils import Error

# PRECEDENCE
precedence = (
    ('right', 'POWER'),
    ('right', 'UPLUS', 'UMINUS', 'NOT'),  
    ('left', 'TIMES', 'DIVIDE', 'FLOOR_DIVIDE', 'MOD'),
    ('left', 'PLUS', 'MINUS'),
    ('left', 'EQUALS', 'NOT_EQUALS', 'LESS_THAN', 'LESS_THAN_EQUALS',
              'GREATER_THAN', 'GREATER_THAN_EQUALS'),
    ('left', 'AND'),
    ('left', 'OR'),
)

def _pos(p, i) -> tuple[int, int]:
    """Returns approximate (line, col) for the i-th symbol of the production."""
    return p.lineno(i), p.lexpos(i)

class Parser:
    """
    Implementation of the **parser**.
    It takes the source code tokenized by the **lexer** and **converts** it into an **Abstract Syntax Tree 
    (AST)** that represents the structure of the code according to the defined grammatical rules. The parser 
    uses **PLY** (Python Lex-Yacc) to build the tree from the tokens generated by the lexer.
    
    - Syntactically analyze language expressions and generate the corresponding AST.
    - Implement operator precedence rules and ensure that expressions are evaluated correctly.  

    """
    tokens = TOKENS
    precedence = precedence

    def __init__(self, debug: bool = False):
        self.debug = debug
        self.errors: List[Error] = []
        self.data: Optional[str] = None

        # Lexer
        self.lexer = Lexer(errors=self.errors, debug=self.debug)
        self.lexer.build()

        self._parser = yacc.yacc(module=self, start="module", debug=self.debug)

    def parse(self, text: str) -> AstNode: # This function receives text and passes it to the lexer for tokenization.
        self.data = text
        if not text.endswith("\n"):
            text += "\n"
        self.lexer.input(text)
        # PLY takes tokens from self.lexer.lex
        return self._parser.parse(lexer=self.lexer.lex, debug=self.debug)

    # ERRORS
    def p_error(self, t):
        if t is None:
            self.errors.append(Error("Unexpected end of input while parsing", 0, 0, "parser", self.data))
            raise SyntaxError(self.errors[-1].exact())
        self.errors.append(Error(f"Syntax error near '{t.value}'", t.lineno, t.lexpos, "parser", self.data))
        raise SyntaxError(self.errors[-1].exact())

    # ESTOP DESPUÉS HAY QUE CAMBIARLO
    # TODO this should be changed: module : stmt_list
    def p_module(self, p):
        "module : expr"
        p[0] = p[1]

    # ********************************************** Rules for expressions *******************************
    
    # It handles the basic components of an expression (such as numbers, strings), atoms. 
    def p_expr_atom(self, p):
        "expr : atom"
        p[0] = p[1]

    # This rule handles expressions grouped in parentheses. Parentheses do not appear in the AST, 
    # pruning is performed.
    def p_expr_group(self, p):
        "expr : LPAREN expr RPAREN"
        p[0] = p[2]

    # ----------------------literals------------------------------------
    # These rules define how to construct nodes for literals in the AST, 
    # such as numbers, strings, True, False, and None.
    def p_atom_number(self, p):
        "atom : NUMBER"
        line, col = _pos(p, 1)
        p[0] = LiteralExpr(value=p[1], line=line, col=col)

    def p_atom_string(self, p):
        "atom : STRING"
        line, col = _pos(p, 1)
        p[0] = LiteralExpr(value=p[1], line=line, col=col)

    def p_atom_true(self, p):
        "atom : TRUE"
        line, col = _pos(p, 1)
        p[0] = LiteralExpr(value=True, line=line, col=col)

    def p_atom_false(self, p):
        "atom : FALSE"
        line, col = _pos(p, 1)
        p[0] = LiteralExpr(value=False, line=line, col=col)

    def p_atom_none(self, p):
        "atom : NONE"
        line, col = _pos(p, 1)
        p[0] = LiteralExpr(value=None, line=line, col=col)

    # Recognizes an isolated identifier as an atom (the simplest element in a expression).
    def p_atom_identifier(self, p):
        "atom : ID"
        line, col = _pos(p, 1)
        p[0] = Identifier(name=p[1], line=line, col=col)

    # ----------------------Unary------------------------------------
    # These rules define how nodes are constructed for unary operators such as +x, -x, not x.
    def p_expr_unary_plus(self, p):
        "expr : PLUS expr %prec UPLUS"
        line, col = _pos(p, 1)
        # Usamos el tipo de token como op; si prefieres, puedes mapear a "+"
        p[0] = UnaryExpr(op='PLUS', operand=p[2], line=line, col=col)

    def p_expr_unary_minus(self, p):
        "expr : MINUS expr %prec UMINUS"
        line, col = _pos(p, 1)
        p[0] = UnaryExpr(op='MINUS', operand=p[2], line=line, col=col)

    def p_expr_unary_not(self, p):
        "expr : NOT expr"
        line, col = _pos(p, 1)
        p[0] = UnaryExpr(op='NOT', operand=p[2], line=line, col=col)

    # ----------------------Binary------------------------------------
    # These rules handle binary operators for exponentiation, multiplication, and addition.
    def p_expr_power(self, p):
        "expr : expr POWER expr %prec POWER"
        line, col = _pos(p, 1)
        p[0] = BinaryExpr(left=p[1], op='**', right=p[3], line=line, col=col)

    # expr * expr, expr / expr, expr // expr, expr % expr
    def p_expr_multiplicative(self, p):
        """expr : expr TIMES expr
                | expr DIVIDE expr
                | expr FLOOR_DIVIDE expr
                | expr MOD expr"""
        line, col = _pos(p, 1)
        p[0] = BinaryExpr(left=p[1], op=p[2], right=p[3], line=line, col=col)

    # expr + expr, expr - expr
    def p_expr_additive(self, p):
        """expr : expr PLUS expr
                | expr MINUS expr"""
        line, col = _pos(p, 1)
        p[0] = BinaryExpr(left=p[1], op=p[2], right=p[3], line=line, col=col)

    # ----------------------comparisons------------------------------------
    # This rule handles comparisons between expressions.
    # expr == expr, expr != expr, expr < expr, expr <= expr, expr > expr, expr >= expr ----
    def p_expr_comparison(self, p):
        """expr : expr EQUALS expr
                | expr NOT_EQUALS expr
                | expr LESS_THAN expr
                | expr LESS_THAN_EQUALS expr
                | expr GREATER_THAN expr
                | expr GREATER_THAN_EQUALS expr"""
        line, col = _pos(p, 1)
        p[0] = ComparisonExpr(left=p[1], op=p[2], right=p[3], line=line, col=col)

    # ----------------------logical------------------------------------
    # This rule handles logical operators.
    # expr and expr, expr or expr ----
    def p_expr_logical(self, p):
        """expr : expr AND expr
                | expr OR expr"""
        line, col = _pos(p, 1)
        p[0] = BinaryExpr(left=p[1], op=p[2], right=p[3], line=line, col=col)

    # ----------------------Function calls------------------------------------
    #This rule handles function calls
    # Function: f(a, b, c) ----
    def p_expr_call(self, p):
        "expr : ID LPAREN arg_list_opt RPAREN"
        line, col = _pos(p, 1)
        p[0] = CallExpr(callee=Identifier(name=p[1], line=line, col=col), args=p[3], line=line, col=col)

    # ----------------------recursive list arg------------------------------------
    # Define one or more expressions separated by commas: a, a, b, a, b, c,... 
    # Use right recursion.
    def p_arg_list_opt(self, p):
        """arg_list_opt : expr COMMA arg_list_opt
                        | expr"""
        if len(p) == 2:
            p[0] = [p[1]]
        else:
            p[0] = [p[1]] + p[3]

    def p_arg_list_opt_empty(self, p):
        "arg_list_opt :"
        p[0] = []
        

  # ********************************************** Rules for Statements *******************************
  # TODO RANDY


  # ********************************************** Rules for Definitions ******************************* 
  # TODO Andrés           

